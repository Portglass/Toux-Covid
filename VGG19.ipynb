{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des modules necessaire :\n",
    "\n",
    "import os\n",
    "\n",
    "import cv2, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "import cv2, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 66 images d'entrainement de patient covid.\n",
      "Il y a 892 images d'entrainement de patient non-covid.\n",
      "\n",
      "Il y a 29 images de validation de patient covid.\n",
      "Il y a 315 images de validation de patient non-covid.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# On declare les chemins vers les donnees :\n",
    "\n",
    "# Image = 'Data'\n",
    "        \n",
    "train_data_dir = 'cleaned_data/spectrogram_train_test/Train'\n",
    "validation_data_dir = 'cleaned_data/spectrogram_train_test/Test'\n",
    "\n",
    "# Dimmension et path :\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "ImageTRAINCOVID = os.listdir(train_data_dir + '/Cov')\n",
    "ImageTRAINNORMAL = os.listdir(train_data_dir + '/noncovid')\n",
    "\n",
    "ImageVALIDATIONCOVID = os.listdir(validation_data_dir + '/Cov')\n",
    "ImageVALIDATIONNORMAL = os.listdir(validation_data_dir + '/noncovid')\n",
    "\n",
    "#ImageTESTCOVID = os.listdir(test_data_dir + '/Covid-19')\n",
    "#ImageTESTNORMAL = os.listdir(test_data_dir + '/spectro_healthy')\n",
    "\n",
    "print('Il y a ' + str(len(ImageTRAINCOVID)) + ' images d\\'entrainement de patient covid.') \n",
    "print('Il y a ' + str(len(ImageTRAINNORMAL)) + ' images d\\'entrainement de patient non-covid.\\n') \n",
    "\n",
    "print('Il y a ' + str(len(ImageVALIDATIONCOVID)) + ' images de validation de patient covid.') \n",
    "print('Il y a ' + str(len(ImageVALIDATIONNORMAL)) + ' images de validation de patient non-covid.\\n')\n",
    "\n",
    "#print('Il y a ' + str(len(ImageTESTCOVID)) + ' images de test de patient covid.') \n",
    "#print('Il y a ' + str(len(ImageTESTNORMAL)) + ' images de test de patient non-covid.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 958 images belonging to 2 classes.\n",
      "Found 344 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing :\n",
    "# On rescale les images :\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# On definit la batch size :\n",
    "batch_size = 32\n",
    "\n",
    "# On prepare les tableaux de donnees depuis les images :\n",
    "train_generator_bottleneck = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "\n",
    "# On prepare les tableaux de donnees depuis les images :\n",
    "validation_generator_bottleneck = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=True)\n",
    "\n",
    "#test_generator_bottleneck = datagen.flow_from_directory(\n",
    "        #test_data_dir,\n",
    "        #target_size=(img_width, img_height),\n",
    "        #batch_size=batch_size,\n",
    "        #class_mode=None,\n",
    "        #shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement de VGG19 sans la partie fully-connected avec le reseau convolutif entrainer sur imagenet :\n",
    "\n",
    "model_vgg = applications.VGG19(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_19880\\1039380922.py:3: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  train_features = model_vgg.predict_generator(train_generator_bottleneck, 958 // batch_size)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_19880\\1039380922.py:4: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  validation_features = model_vgg.predict_generator(validation_generator_bottleneck, 344 // batch_size)\n"
     ]
    }
   ],
   "source": [
    "# On utilse le model VGG16 pour extraire les features de nos images \n",
    "# (on fait recupere la sortie du reseau convolutionnel) :\n",
    "train_features = model_vgg.predict_generator(train_generator_bottleneck, 958 // batch_size)\n",
    "validation_features = model_vgg.predict_generator(validation_generator_bottleneck, 344 // batch_size)\n",
    "#test_features = model_vgg.predict_generator(test_generator_bottleneck, 1560 // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L'opération étant longue on enregistre les features obtenus :\n",
    "\n",
    "np.save(open('models/trainFeatures_VGG19_AllData.npy', 'wb'), train_features) # ecriture en binaire necessaire\n",
    "np.save(open('models/validationFeatures_VGG19_AllData.npy', 'wb'), validation_features) # Idem\n",
    "\n",
    "#np.save(open('models/testFeatures_VGG16_AllData.npy', 'wb'), test_features) # Idem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2372362487.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [44]\u001b[1;36m\u001b[0m\n\u001b[1;33m    validation_features = np.load(open('mod'binary'els/validationFeatures_VGG19_AllData.npy', 'rb'))\u001b[0m\n\u001b[1;37m                                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Si l'operation à deja été effectuer on charge les features :\n",
    "\n",
    "train_features = np.load(open('models/trainFeatures_VGG19_AllData.npy', 'rb'))\n",
    "validation_features = np.load(open('mod'binary'els/validationFeatures_VGG19_AllData.npy', 'rb'))\n",
    "\n",
    "#test_features = np.load(open('models/testFeatures_VGG16_AllData.npy', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array([0] * 66 + [1] * 892 )\n",
    "validation_labels = np.array([0] * 29 + [1] * 315 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_4 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 256)               6422784   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,423,041\n",
      "Trainable params: 6,423,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Troisieme modele :\n",
    "model_top3 = Sequential()\n",
    "model_top3.add(Flatten(input_shape=train_features.shape[1:])) #Flatten layers are used when you got a multidimensional output and you want to make it linear to pass it onto a Dense layer.\n",
    "model_top3.add(Dense(256, activation='relu')) #Dense layers are used when association can exist among any feature to any other feature in data point.\n",
    "model_top3.add(Dropout(0.5)) #Dropout is a way of cutting too much association among features by dropping the weights (edges) at a probability.\n",
    "model_top3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# On compile :\n",
    "model_top3.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# On affiche :\n",
    "model_top3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On definit les parametres pour l'entrainement :\n",
    "epochs = 100\n",
    "\n",
    "# On definit les callbacks : \n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='accuracy',mode='max',patience = 10,restore_best_weights=True,),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\marti\\anaconda3\\envs\\covid_cough\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\marti\\anaconda3\\envs\\covid_cough\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\marti\\anaconda3\\envs\\covid_cough\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\marti\\anaconda3\\envs\\covid_cough\\lib\\site-packages\\keras\\engine\\training.py\", line 861, in train_step\n        self._validate_target_and_loss(y, loss)\n    File \"C:\\Users\\marti\\anaconda3\\envs\\covid_cough\\lib\\site-packages\\keras\\engine\\training.py\", line 818, in _validate_target_and_loss\n        raise ValueError(\n\n    ValueError: Target data is missing. Your model was compiled with loss=binary_crossentropy, and therefore expects target data to be provided in `fit()`.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# On entraine le modèle:\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m historique3 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_top3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator_bottleneck\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmy_callbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator_bottleneck\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\covid_cough\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\covid_cough\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m   1148\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\marti\\anaconda3\\envs\\covid_cough\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\marti\\anaconda3\\envs\\covid_cough\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\marti\\anaconda3\\envs\\covid_cough\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\marti\\anaconda3\\envs\\covid_cough\\lib\\site-packages\\keras\\engine\\training.py\", line 861, in train_step\n        self._validate_target_and_loss(y, loss)\n    File \"C:\\Users\\marti\\anaconda3\\envs\\covid_cough\\lib\\site-packages\\keras\\engine\\training.py\", line 818, in _validate_target_and_loss\n        raise ValueError(\n\n    ValueError: Target data is missing. Your model was compiled with loss=binary_crossentropy, and therefore expects target data to be provided in `fit()`.\n"
     ]
    }
   ],
   "source": [
    "# On entraine le modèle:\n",
    "historique3 = model_top3.fit(train_generator_bottleneck,\n",
    "        epochs=epochs, \n",
    "        callbacks = my_callbacks,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=validation_generator_bottleneck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = len(historique3.history['accuracy'])\n",
    "GenOptimale3 = n_epochs-10\n",
    "print(\"La generation optimale est : \",GenOptimale3)\n",
    "print(\"Avec une accuracy de : \",historique3.history['accuracy'][GenOptimale3-1])\n",
    "model_top3.save_weights('models/weights/vgg19_heavyTop_224_224_'+str(GenOptimale3)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1,n_epochs+1)\n",
    "plt.plot(epochs, historique3.history['accuracy'], label='Accuracy')\n",
    "plt.plot(epochs, historique3.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.plot(epochs, historique3.history['loss'], label='Loss')\n",
    "plt.plot(epochs, historique3.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation loss and accuracy for the heavy layer fully connected')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On evalue :\n",
    "\n",
    "# Avec les donnes de validation :\n",
    "eval3 = model_top3.evaluate(validation_features, validation_labels,verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covid_cough",
   "language": "python",
   "name": "covid_cough"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
